{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f535f-fd11-4a36-8bdf-5afe2442852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import xarray as xr\n",
    "import os\n",
    "import requests\n",
    "import urllib.request\n",
    "import IPython.display as display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b500f9f-fd68-44d3-8d4b-8f15280b68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "data_dir = \"../project1\"\n",
    "hurricane_nc_path = os.path.join(data_dir, \"IBTrACS.NA.v04r00.nc\")\n",
    "enso_path = os.path.join(data_dir, \"enso_data.txt\")\n",
    "\n",
    "# Ensure the data directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download IBTrACS Hurricane Data if not found\n",
    "ibtracs_url = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/netcdf/IBTrACS.NA.v04r00.nc\"\n",
    "\n",
    "if not os.path.exists(hurricane_nc_path):\n",
    "    print(\"Downloading IBTrACS hurricane data...\")\n",
    "    try:\n",
    "        response = requests.get(ibtracs_url, timeout=60)\n",
    "        response.raise_for_status()  # Raise an error if the request failed\n",
    "        with open(hurricane_nc_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"IBTrACS file downloaded successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "\n",
    "# Load NetCDF hurricane data\n",
    "try:\n",
    "    ds = xr.open_dataset(hurricane_nc_path)\n",
    "except Exception as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "\n",
    "# Convert NetCDF dataset to Pandas DataFrame\n",
    "df_hurricane = ds.to_dataframe().reset_index()\n",
    "\n",
    "# Select relevant columns based on dataset structure\n",
    "df_hurricane = df_hurricane.loc[:, [\"sid\", \"season\", \"time\", \"lat\", \"lon\", \"usa_wind\"]].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_hurricane.columns = [\"Storm_ID\", \"Year\", \"ISO_Time\", \"Latitude\", \"Longitude\", \"Storm_Intensity\"]\n",
    "\n",
    "# Decode `sid` from bytes to string\n",
    "df_hurricane[\"Storm_ID\"] = df_hurricane[\"Storm_ID\"].str.decode(\"utf-8\")\n",
    "\n",
    "# Convert Year to integer (from float)\n",
    "df_hurricane[\"Year\"] = df_hurricane[\"Year\"].astype(int)\n",
    "\n",
    "# Filter years from 1950 onwards\n",
    "df_hurricane = df_hurricane[df_hurricane[\"Year\"] >= 1950]\n",
    "\n",
    "# Convert `ISO_Time` to datetime format\n",
    "df_hurricane[\"ISO_Time\"] = pd.to_datetime(df_hurricane[\"ISO_Time\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where conversion failed\n",
    "df_hurricane = df_hurricane.dropna(subset=[\"ISO_Time\"])\n",
    "\n",
    "# Extract Month safely\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"ISO_Time\"].dt.month.astype(int)\n",
    "\n",
    "# Convert Month from number to text for merging with ENSO\n",
    "month_map = {\n",
    "    1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
    "    7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"\n",
    "}\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"Month\"].map(month_map)\n",
    "\n",
    "# Define hurricane category mapping (based on wind speed in knots)\n",
    "def categorize_hurricane(wind_speed):\n",
    "    if wind_speed < 64:\n",
    "        return \"Tropical Storm\"\n",
    "    elif 64 <= wind_speed <= 82:\n",
    "        return \"Category 1\"\n",
    "    elif 83 <= wind_speed <= 95:\n",
    "        return \"Category 2\"\n",
    "    elif 96 <= wind_speed <= 112:\n",
    "        return \"Category 3\"\n",
    "    elif 113 <= wind_speed <= 136:\n",
    "        return \"Category 4\"\n",
    "    else:\n",
    "        return \"Category 5\"\n",
    "\n",
    "# Apply category mapping\n",
    "df_hurricane[\"Category\"] = df_hurricane[\"Storm_Intensity\"].apply(categorize_hurricane)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_hurricane.to_csv(\"../project1/hurricane_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a223de-e5a3-4854-b675-0f9efc696c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning ENSO table\n",
    "\n",
    "# Load ENSO data\n",
    "df_enso = pd.read_csv(enso_path, sep=r'\\s+', header=None)\n",
    "\n",
    "# Rename columns\n",
    "df_enso.columns = [\"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "# Remove non-numeric rows (e.g., headers, footers)\n",
    "df_enso = df_enso[df_enso[\"Year\"].astype(str).str.match(r'^\\d{4}$')]\n",
    "\n",
    "# Convert Year to integer\n",
    "df_enso[\"Year\"] = df_enso[\"Year\"].astype(int)\n",
    "\n",
    "# Convert to long format\n",
    "df_enso_long = df_enso.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"SST_Anomaly\")\n",
    "\n",
    "# Convert SST_Anomaly to numeric\n",
    "df_enso_long[\"SST_Anomaly\"] = pd.to_numeric(df_enso_long[\"SST_Anomaly\"], errors=\"coerce\")\n",
    "\n",
    "# Sort values (important for applying 5-month rule)\n",
    "df_enso_long = df_enso_long.sort_values(by=[\"Year\", \"Month\"]).reset_index(drop=True)\n",
    "\n",
    "# Initialize ENSO phase column\n",
    "df_enso_long[\"ENSO_Phase\"] = \"Neutral\"\n",
    "\n",
    "# Function to apply 5-month rule\n",
    "def detect_enso_events(df):\n",
    "    consecutive_count = 0\n",
    "    current_phase = \"Neutral\"\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        anomaly = df.loc[i, \"SST_Anomaly\"]\n",
    "\n",
    "        # Determine the phase for this month\n",
    "        if anomaly >= 0.5:\n",
    "            phase = \"El Niño\"\n",
    "        elif anomaly <= -0.5:\n",
    "            phase = \"La Niña\"\n",
    "        else:\n",
    "            phase = \"Neutral\"\n",
    "\n",
    "        # If we are continuing the same phase, increase count\n",
    "        if phase == current_phase:\n",
    "            consecutive_count += 1\n",
    "        else:\n",
    "            # If we switch phases, reset the counter\n",
    "            consecutive_count = 1\n",
    "            current_phase = phase\n",
    "\n",
    "        # If phase has lasted for at least 5 months, apply to previous months\n",
    "        if consecutive_count >= 5:\n",
    "            for j in range(i - 4, i + 1):\n",
    "                df.loc[j, \"ENSO_Phase\"] = current_phase  # Apply to previous 5 months\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply 5-month rule\n",
    "df_enso_long = detect_enso_events(df_enso_long)\n",
    "df_enso_long.to_csv(\"../project1/enso_cleaned.csv\", index=False)\n",
    "df_enso_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abca3d-3813-460a-9259-6f0110fa95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge ENSO and hurricane data together\n",
    "df_hurricane[\"Year\"] = df_hurricane[\"Year\"].astype(int)\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"Month\"].astype(str)\n",
    "\n",
    "df_enso_long[\"Year\"] = df_enso_long[\"Year\"].astype(int)\n",
    "df_enso_long[\"Month\"] = df_enso_long[\"Month\"].astype(str)\n",
    "df_enso_long = df_enso_long[df_enso_long[\"Year\"] >= 1950]\n",
    "\n",
    "# Define a dictionary to map abbreviated month names to full names\n",
    "month_map = {\n",
    "    \"Jan\": \"January\", \"Feb\": \"February\", \"Mar\": \"March\", \"Apr\": \"April\", \"May\": \"May\", \"Jun\": \"June\",\n",
    "    \"Jul\": \"July\", \"Aug\": \"August\", \"Sep\": \"September\", \"Oct\": \"October\", \"Nov\": \"November\", \"Dec\": \"December\"\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"Month\"].map(month_map)\n",
    "df_enso_long.loc[:, \"Month\"] = df_enso_long[\"Month\"].map(month_map)\n",
    "\n",
    "# Ensure all Month values are consistent by stripping spaces\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"Month\"].str.strip()\n",
    "df_enso_long.loc[:, \"Month\"] = df_enso_long[\"Month\"].str.strip()\n",
    "\n",
    "# Convert to lowercase (optional but helps prevent mismatches)\n",
    "df_hurricane[\"Month\"] = df_hurricane[\"Month\"].str.capitalize()\n",
    "df_enso_long.loc[:, \"Month\"] = df_enso_long[\"Month\"].str.capitalize()\n",
    "df_hurricane = df_hurricane[df_hurricane[\"Year\"] >= 1950]\n",
    "\n",
    "# Merge hurricane data with ENSO data on Year & Month\n",
    "df_merged_ENSO = df_hurricane.merge(df_enso_long, on=[\"Year\", \"Month\"], how=\"left\")\n",
    "\n",
    "# Save merged dataset\n",
    "df_merged_ENSO.to_csv(\"../project1/merged_enso.csv\", index=False)\n",
    "\n",
    "df_merged_ENSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc61c4-e20b-45a4-921c-a26a0a4a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate by Month (Average SST anomaly per month across years)\n",
    "df_monthly = df_enso_long.groupby([\"Year\", \"Month\"])[\"SST_Anomaly\"].mean().reset_index()\n",
    "\n",
    "# Set up figure\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define ENSO colors\n",
    "enso_colors = df_monthly[\"SST_Anomaly\"].apply(lambda x: \"red\" if x >= 0.5 else \"blue\" if x <= -0.5 else \"gray\")\n",
    "\n",
    "# Create bar plot for monthly SST anomalies\n",
    "plt.bar(df_monthly.index, df_monthly[\"SST_Anomaly\"], color=enso_colors, width=1.0, alpha=0.7)\n",
    "\n",
    "# Add smoothed 5-year rolling mean to show ENSO variability over time\n",
    "df_monthly[\"Rolling_MEI\"] = df_monthly[\"SST_Anomaly\"].rolling(60, min_periods=1).mean()\n",
    "plt.plot(df_monthly.index, df_monthly[\"Rolling_MEI\"], color=\"black\", linewidth=1.5, label=\"Smoothed ENSO Index (5-Year Rolling Mean)\")\n",
    "\n",
    "# Add zero reference line\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Time (1950-2023)\", fontsize=12)\n",
    "plt.ylabel(\"SST Anomaly (°C)\", fontsize=12)\n",
    "plt.title(\"ENSO Variability Over Time (Monthly SST Anomalies)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Format x-axis\n",
    "plt.xticks(np.arange(0, len(df_monthly), step=120), df_monthly[\"Year\"].iloc[::120].astype(int), rotation=45)  # Show every 10 years\n",
    "plt.ylim(-2.5, 3)\n",
    "\n",
    "# Add grid for readability\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [\n",
    "    plt.Line2D([0], [0], color=\"red\", linewidth=4, label=\"El Niño (≥ 0.5)\"),\n",
    "    plt.Line2D([0], [0], color=\"blue\", linewidth=4, label=\"La Niña (≤ -0.5)\"),\n",
    "    plt.Line2D([0], [0], color=\"gray\", linewidth=4, label=\"Neutral (-0.5 to 0.5)\"),\n",
    "    plt.Line2D([0], [0], color=\"black\", linewidth=1.5, label=\"Smoothed ENSO Index\")\n",
    "]\n",
    "plt.legend(handles=legend_labels, loc=\"upper left\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c14f52-21c6-4887-b8f0-9d1a4c02e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to classify hurricanes based on max wind speed\n",
    "def categorize_hurricane(max_wind_speed):\n",
    "    \"\"\"Classify hurricanes based on maximum wind speed\"\"\"\n",
    "    if 34 <= max_wind_speed < 64:\n",
    "        return \"Tropical Storm\"\n",
    "    elif max_wind_speed < 83:\n",
    "        return \"Category 1\"\n",
    "    elif max_wind_speed < 96:\n",
    "        return \"Category 2\"\n",
    "    elif max_wind_speed < 113:\n",
    "        return \"Category 3\"\n",
    "    elif max_wind_speed < 137:\n",
    "        return \"Category 4\"\n",
    "    else:\n",
    "        return \"Category 5\"\n",
    "\n",
    "# Function to plot ENSO phase comparison\n",
    "def plot_enso_comparison(df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot hurricane tracks for different ENSO phases (El Niño, La Niña).\n",
    "    \"\"\"\n",
    "    # Create a 6x2 grid of subplots\n",
    "    fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "    # Define categories and colors\n",
    "    category_colors = {\n",
    "        \"Tropical Storm\": (144/255, 238/255, 144/255),    # Light green\n",
    "        \"Category 1\": (238/255, 232/255, 170/255),        # Light yellow\n",
    "        \"Category 2\": (244/255, 164/255, 96/255),         # Light orange\n",
    "        \"Category 3\": (233/255, 150/255, 122/255),        # Light red\n",
    "        \"Category 4\": (221/255, 160/255, 221/255),        # Light purple\n",
    "        \"Category 5\": (147/255, 112/255, 219/255)         # Dark purple\n",
    "    }\n",
    "\n",
    "    categories = [\"Category 5\", \"Category 4\", \"Category 3\", \n",
    "                  \"Category 2\", \"Category 1\", \"Tropical Storm\"]\n",
    "    phases = [\"El Niño\", \"La Niña\"]\n",
    "\n",
    "    for cat_idx, category in enumerate(categories):\n",
    "        for phase_idx, phase in enumerate(phases):\n",
    "            ax = plt.subplot(6, 2, cat_idx * 2 + phase_idx + 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "            # Set map extent\n",
    "            ax.set_extent([-100, 0, 0, 60], crs=ccrs.PlateCarree())\n",
    "\n",
    "            # Add natural geographic features\n",
    "            ax.add_feature(cfeature.LAND, edgecolor='black', facecolor=\"beige\")\n",
    "            ax.add_feature(cfeature.OCEAN, facecolor=cfeature.COLORS['water'])\n",
    "            ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "            ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "            # Add gridlines\n",
    "            gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False if phase_idx == 0 else False\n",
    "            gl.left_labels = True if phase_idx == 0 else False\n",
    "\n",
    "            # Filter data\n",
    "            storm_ids = df[df['Category'] == category]['Storm_ID'].unique()\n",
    "            storm_data = df[df['Storm_ID'].isin(storm_ids) & (df['ENSO_Phase'] == phase)]\n",
    "\n",
    "            if len(storm_data) > 0:\n",
    "                plotted_storms = set()\n",
    "                for storm_id in storm_data['Storm_ID'].unique():\n",
    "                    if storm_id in plotted_storms:\n",
    "                        continue\n",
    "\n",
    "                    track = df[df['Storm_ID'] == storm_id].sort_values('ISO_Time')\n",
    "                    track = track.iloc[::16, :]  # Reduce point density\n",
    "\n",
    "                    # Plot track line\n",
    "                    ax.plot(track['Longitude'], track['Latitude'],\n",
    "                            color='black',\n",
    "                            linewidth=0.8,\n",
    "                            alpha=0.4,\n",
    "                            zorder=2)\n",
    "\n",
    "                    # Add points\n",
    "                    ax.scatter(track['Longitude'], track['Latitude'],\n",
    "                               color=category_colors[category],\n",
    "                               s=15,\n",
    "                               alpha=0.6,\n",
    "                               edgecolor='black',\n",
    "                               linewidth=0.5,\n",
    "                               zorder=3)\n",
    "\n",
    "                    plotted_storms.add(storm_id)\n",
    "\n",
    "            # Add subplot title\n",
    "            storm_count = len(set(storm_data['Storm_ID']))\n",
    "            ax.set_title(f\"{category} - {phase}\\n({storm_count} storms)\", fontsize=12, pad=10)\n",
    "\n",
    "    # Add overall title\n",
    "    plt.suptitle(\"1950-2023 North Atlantic Hurricanes by ENSO Phase\", fontsize=16, y=0.92)\n",
    "\n",
    "    # Adjust subplot spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Read data\n",
    "    df = pd.read_csv('merged_enso.csv')\n",
    "\n",
    "    # Convert date and extract year\n",
    "    df['Year'] = pd.to_datetime(df['ISO_Time']).dt.year\n",
    "\n",
    "    # Restrict time range to 1950-2023\n",
    "    df = df[(df['Year'] >= 1950) & (df['Year'] <= 2023)]\n",
    "\n",
    "    # Get maximum intensity for each storm\n",
    "    max_intensities = df.groupby('Storm_ID')['Storm_Intensity'].max()\n",
    "    df['Category'] = df['Storm_ID'].map(lambda x: categorize_hurricane(max_intensities[x]))\n",
    "\n",
    "    # Assign ENSO phase based on SST anomaly\n",
    "    df['ENSO_Phase'] = df['SST_Anomaly'].apply(lambda x: 'El Niño' if x > 0.5 else 'La Niña' if x < -0.5 else 'Neutral')\n",
    "\n",
    "    # Generate phase comparison plot\n",
    "    plot_enso_comparison(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b075815-dbd3-42d1-95e0-6293aaaea633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Frequency of hurricanes during different ENSO stages\n",
    "\n",
    "# Ensure ENSO Phase is categorized correctly\n",
    "df_merged_ENSO[\"ENSO_Phase\"] = df_merged_ENSO[\"ENSO_Phase\"].astype(str)\n",
    "\n",
    "# Total length (years) per ENSO Phase\n",
    "total_years = df_merged_ENSO.groupby(\"ENSO_Phase\")[\"Year\"].nunique()\n",
    "\n",
    "# Number of unique hurricanes per ENSO Phase\n",
    "num_hurricanes = df_merged_ENSO.groupby(\"ENSO_Phase\")[\"Storm_ID\"].nunique()\n",
    "\n",
    "# Hurricanes per year per ENSO Phase\n",
    "hurricanes_per_year = num_hurricanes / total_years\n",
    "\n",
    "# Combine into a DataFrame\n",
    "enso_summary = pd.DataFrame({\n",
    "    \"Total Length (years)\": total_years,\n",
    "    \"# Of Hurricanes\": num_hurricanes,\n",
    "    \"Hurricanes/Year\": hurricanes_per_year\n",
    "})\n",
    "\n",
    "# Reset index for better readability\n",
    "enso_summary = enso_summary.reset_index()\n",
    "\n",
    "# Display the summary table\n",
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=enso_summary.values, colLabels=enso_summary.columns, cellLoc='center', loc='center')\n",
    "\n",
    "# Formatting the header row\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:  # Header row\n",
    "        cell.set_text_props(weight='bold')\n",
    "\n",
    "# Show the table\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391f929-bac7-4fc1-b69f-62263ddd6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate moment for a storm\n",
    "\n",
    "def get_first_moment(df):\n",
    "    \"\"\"Computes the first moment (mean latitude & longitude) of a hurricane track.\"\"\"\n",
    "    if df.empty:\n",
    "        return None  # Handle empty cases\n",
    "\n",
    "    mean_lat = df[\"Latitude\"].mean()\n",
    "    mean_lon = df[\"Longitude\"].mean()\n",
    "    return [mean_lon, mean_lat]  # Longitude first for mapping consistency\n",
    "\n",
    "# Compute first moments for each unique hurricane track\n",
    "moment_lst = [get_first_moment(df_merged_ENSO[df_merged_ENSO[\"Storm_ID\"] == storm])\n",
    "              for storm in df_merged_ENSO[\"Storm_ID\"].unique()]\n",
    "\n",
    "# Remove any None values (cases where hurricanes had missing data)\n",
    "moment_lst = [m for m in moment_lst if m is not None]\n",
    "\n",
    "# Convert to NumPy array for clustering\n",
    "moment_arr = np.array(moment_lst)\n",
    "\n",
    "print(f\"Computed first moments for {len(moment_arr)} hurricane tracks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70dbf6-3ac7-4512-9585-af3c6d39d045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find number of clusters using Elbow-Method\n",
    "\n",
    "# Initialize a list to store sum of squared distances (inertia)\n",
    "sum_of_squares = []\n",
    "K_range = range(1, 15)  # Testing K from 1 to 14\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(moment_arr)\n",
    "    sum_of_squares.append(kmeans.inertia_)  # Store inertia value\n",
    "\n",
    "# Plot the Elbow Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, sum_of_squares, 'bo-', markersize=6)  # Blue circles with a line\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances (Inertia)')\n",
    "plt.title('Elbow Method for Optimal Cluster Selection')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727ef38-1e6a-4f51-8b94-f8e1c68970ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-clustering of ENSO's impact on hurricanes\n",
    "\n",
    "# Define map extent (adjust if needed)\n",
    "extent = [-100, 0, 0, 60]  # Longitude and Latitude bounds\n",
    "\n",
    "# Define optimal k from elbow method\n",
    "optimal_k = 2  # Change this based on the elbow method result\n",
    "\n",
    "# Apply K-Means clustering to first-moment hurricane tracks\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(moment_lst)\n",
    "\n",
    "# Define cluster colors (extend list if more clusters are needed)\n",
    "colors = ['black', 'red', 'blue', 'yellow', 'green', 'magenta']\n",
    "\n",
    "# Plot first-moment clustering results\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = map_background(extent, title=\"K-Means Clustering of Hurricane Tracks\")\n",
    "\n",
    "# Plot each cluster with assigned color\n",
    "for i, moment in enumerate(moment_lst):\n",
    "    ax.plot(moment[0], moment[1], c=colors[labels[i]], marker='*')\n",
    "\n",
    "plt.title(f'K-Means Clustering Result ({optimal_k} Clusters)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecbeb5-9b9a-4634-a1ef-76e8437527fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge AMO data with Hurricane NA Basin data\n",
    "\n",
    "#Load AMO data\n",
    "amo_path = \"../project1/csu_amo.csv\"\n",
    "df_amo = pd.read_csv(amo_path)\n",
    "\n",
    "#Filter Hurricane data to start at 1950\n",
    "df_hurricane = df_hurricane[df_hurricane[\"Year\"] >= 1950]\n",
    "\n",
    "# Convert AMO data to long format\n",
    "df_amo_long = df_amo.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"AMO_Anomaly\")\n",
    "\n",
    "# Ensure Month names match the hurricane dataset\n",
    "month_map = {\n",
    "    \"Jan\": \"January\", \"Feb\": \"February\", \"Mar\": \"March\", \"Apr\": \"April\", \"May\": \"May\", \"Jun\": \"June\",\n",
    "    \"Jul\": \"July\", \"Aug\": \"August\", \"Sep\": \"September\", \"Oct\": \"October\", \"Nov\": \"November\", \"Dec\": \"December\"\n",
    "}\n",
    "df_amo_long[\"Month\"] = df_amo_long[\"Month\"].map(month_map)\n",
    "\n",
    "# Convert data types to match hurricane dataset\n",
    "df_amo_long[\"Year\"] = df_amo_long[\"Year\"].astype(int)\n",
    "df_amo_long[\"Month\"] = df_amo_long[\"Month\"].astype(str)\n",
    "\n",
    "print(df_amo_long.head())  # Check transformed data\n",
    "\n",
    "df_merge_amo = df_hurricane.merge(df_amo_long, on=[\"Year\", \"Month\"], how=\"left\")\n",
    "\n",
    "# Save merged dataset\n",
    "df_merge_amo.to_csv(\"../project1/merged_amo.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f9e85-135a-4e48-9ab0-cdd5af809982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to classify hurricanes based on wind speed\n",
    "def categorize_hurricane(max_wind_speed):\n",
    "    \"\"\"Classify hurricanes based on maximum wind speed\"\"\"\n",
    "    if 34 <= max_wind_speed < 64:\n",
    "        return \"Tropical Storm\"\n",
    "    elif max_wind_speed < 83:\n",
    "        return \"Category 1\"\n",
    "    elif max_wind_speed < 96:\n",
    "        return \"Category 2\"\n",
    "    elif max_wind_speed < 113:\n",
    "        return \"Category 3\"\n",
    "    elif max_wind_speed < 137:\n",
    "        return \"Category 4\"\n",
    "    else:\n",
    "        return \"Category 5\"\n",
    "\n",
    "# Read and process the ENSO dataset\n",
    "df = df_merged_ENSO.copy()\n",
    "\n",
    "# Convert date and limit time range to 1950-2020\n",
    "df['Date'] = pd.to_datetime(df['ISO_Time'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df = df[(df['Year'] >= 1950) & (df['Year'] <= 2020)]\n",
    "\n",
    "# Get maximum hurricane intensity for each storm\n",
    "max_intensities = df.groupby('Storm_ID')['Storm_Intensity'].max()\n",
    "unique_storms = df.drop_duplicates('Storm_ID').copy()\n",
    "unique_storms['Max_Intensity'] = unique_storms['Storm_ID'].map(max_intensities)\n",
    "\n",
    "# Categorize hurricanes by intensity\n",
    "unique_storms['Category'] = unique_storms['Storm_ID'].map(lambda x: categorize_hurricane(max_intensities[x]))\n",
    "\n",
    "# Define ENSO phases\n",
    "unique_storms['ENSO_Phase'] = unique_storms['SST_Anomaly'].apply(\n",
    "    lambda x: 'El Niño' if x > 0.5 else 'La Niña' if x < -0.5 else 'Neutral'\n",
    ")\n",
    "\n",
    "# Create yearly statistics\n",
    "yearly_data = pd.DataFrame(index=range(1950, 2021))\n",
    "yearly_data['ENSO_Phase'] = unique_storms.groupby('Year')['ENSO_Phase'].first()\n",
    "\n",
    "# Count number of years in each phase\n",
    "phase_years = yearly_data['ENSO_Phase'].value_counts()\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Define colors for hurricane categories\n",
    "category_colors = {\n",
    "    \"Tropical Storm\": \"gray\",\n",
    "    \"Category 1\": \"yellow\",\n",
    "    \"Category 2\": \"orange\",\n",
    "    \"Category 3\": \"red\",\n",
    "    \"Category 4\": \"purple\",\n",
    "    \"Category 5\": \"black\"\n",
    "}\n",
    "\n",
    "# Colors for ENSO phases (dynamically mapped)\n",
    "phase_colors_map = {'El Niño': '#FF9999', 'La Niña': '#99CCFF', 'Neutral': '#CCCCCC'}\n",
    "existing_phases = list(unique_storms['ENSO_Phase'].unique())  # Get actual phases in data\n",
    "phase_colors = [phase_colors_map[phase] for phase in existing_phases]\n",
    "\n",
    "### **1️⃣ Category Distribution by ENSO Phase**\n",
    "plt.subplot(2, 2, 1)\n",
    "category_order = [\"Category 5\", \"Category 4\", \"Category 3\", \"Category 2\", \"Category 1\", \"Tropical Storm\"]\n",
    "cat_counts = pd.crosstab(unique_storms['ENSO_Phase'], unique_storms['Category'])\n",
    "\n",
    "# Ensure cat_counts allows float values\n",
    "cat_counts = cat_counts.astype(float)\n",
    "\n",
    "# Normalize by years in each phase\n",
    "for phase in cat_counts.index:\n",
    "    cat_counts.loc[phase] = (cat_counts.loc[phase] / phase_years[phase]).astype(float)\n",
    "\n",
    "cat_counts = cat_counts[category_order]\n",
    "\n",
    "ax = cat_counts.plot(kind='bar', ax=plt.gca(), \n",
    "                     color=[category_colors[cat] for cat in category_order])\n",
    "plt.title('Average Annual Hurricane Category Distribution by ENSO Phase\\n(1950-2020)', fontsize=14, pad=20)\n",
    "plt.xlabel('ENSO Phase', fontsize=12)\n",
    "plt.ylabel('Average Number of Storms per Year', fontsize=12)\n",
    "plt.legend(title='Hurricane Category', bbox_to_anchor=(1.05, 1))\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "### **2️⃣ Monthly Hurricane Distribution by ENSO Phase**\n",
    "plt.subplot(2, 2, 2)\n",
    "unique_storms['Month'] = unique_storms['Date'].dt.month\n",
    "monthly_counts = pd.crosstab(unique_storms['ENSO_Phase'], unique_storms['Month'])\n",
    "\n",
    "# Ensure all months are present\n",
    "for month in range(1, 13):\n",
    "    if month not in monthly_counts.columns:\n",
    "        monthly_counts[month] = 0\n",
    "monthly_counts = monthly_counts.reindex(columns=range(1, 13)).fillna(0)\n",
    "monthly_counts = monthly_counts.astype(float)\n",
    "\n",
    "# Normalize by years in each ENSO phase\n",
    "for phase in monthly_counts.index:\n",
    "    monthly_counts.loc[phase] = monthly_counts.loc[phase].astype(float) / float(phase_years[phase])\n",
    "\n",
    "month_names = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "for i, phase in enumerate(existing_phases):\n",
    "    plt.plot(range(len(month_names)), monthly_counts.loc[phase], \n",
    "             marker='o', label=phase, color=phase_colors[i], linewidth=2)\n",
    "\n",
    "plt.title('Average Monthly Hurricane Distribution by ENSO Phase\\n(1950-2020)', fontsize=14, pad=20)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Average Number of Storms per Year', fontsize=12)\n",
    "plt.legend()\n",
    "plt.xticks(range(len(month_names)), month_names, rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "### **3️⃣ Violin Plot: Max Intensity by ENSO Phase**\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.violinplot(data=unique_storms, x='ENSO_Phase', y='Max_Intensity', hue='ENSO_Phase', \n",
    "               palette=phase_colors, legend=False)\n",
    "plt.title('Maximum Storm Intensity Distribution by ENSO Phase\\n(1950-2020)', fontsize=14, pad=20)\n",
    "plt.xlabel('ENSO Phase', fontsize=12)\n",
    "plt.ylabel('Maximum Storm Intensity (knots)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "### **4️⃣ Scatter Plot: Max Intensity vs ENSO Anomaly**\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(unique_storms['SST_Anomaly'], unique_storms['Max_Intensity'], \n",
    "            c=unique_storms['SST_Anomaly'], cmap='RdBu_r', alpha=0.6, s=30)\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(unique_storms['SST_Anomaly'], unique_storms['Max_Intensity'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_range = np.linspace(unique_storms['SST_Anomaly'].min(), unique_storms['SST_Anomaly'].max(), 100)\n",
    "plt.plot(x_range, p(x_range), color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add correlation coefficient\n",
    "correlation = np.corrcoef(unique_storms['SST_Anomaly'], unique_storms['Max_Intensity'])[0,1]\n",
    "plt.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "         transform=plt.gca().transAxes, fontsize=10)\n",
    "\n",
    "plt.title('Maximum Storm Intensity vs ENSO Anomaly\\n(1950-2020)', fontsize=14, pad=20)\n",
    "plt.xlabel('SST Anomaly', fontsize=12)\n",
    "plt.ylabel('Maximum Storm Intensity (knots)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistical summary\n",
    "print(\"\\nStatistical Summary (1950-2020):\")\n",
    "print(f\"\\nAnalysis period: 1950-2023 ({len(yearly_data)} years)\")\n",
    "print(\"\\nTotal number of storms per ENSO phase:\")\n",
    "print(unique_storms['ENSO_Phase'].value_counts())\n",
    "\n",
    "print(\"\\nAverage Maximum Intensity per ENSO Phase:\")\n",
    "print(unique_storms.groupby('ENSO_Phase')['Max_Intensity'].agg(['mean', 'std', 'count']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277bcf4-9440-4195-9b52-77eb3ebb56fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
